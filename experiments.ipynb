{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5db9669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsaxena/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "#Importing Ollama: Llama2(7B) model\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "\n",
    "#Importing Prompt Templates\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "#Importing Vector Databases\n",
    "import pinecone\n",
    "from langchain_pinecone import PineconeVectorStore as Pinecone\n",
    "\n",
    "#Importing Embeddings Models\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#Import QA chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#Import document loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "#Import recursive text splitter for chunking documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#Packages to load enviourmennt variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53af93ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b57868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Ollama model\n",
    "llm= Ollama(\n",
    "    model= \"llama2:7b\",\n",
    "    temperature=0.4,\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c91a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsaxena/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=d4b4477e-4d67-44e2-b70f-8e4df7042d03,id=d4b4477e-4d67-44e2-b70f-8e4df7042d03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The capital of France is Paris.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=d4b4477e-4d67-44e2-b70f-8e4df7042d03,id=d4b4477e-4d67-44e2-b70f-8e4df7042d03\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=c5479c01-f07c-4c96-82fb-c501b62bea7c; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=bd6fabcb-f72b-4727-85ca-c5094753a9ac\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=0bd16572-7f3a-4b32-869a-1700ea7c6f79; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=5170d0da-d40b-4d1c-947a-0b29fb1001e0; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=6c955a1c-68c8-4b23-9f95-7d58ed136864; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=bd6fabcb-f72b-4727-85ca-c5094753a9ac\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=6c955a1c-68c8-4b23-9f95-7d58ed136864; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=5170d0da-d40b-4d1c-947a-0b29fb1001e0; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=0bd16572-7f3a-4b32-869a-1700ea7c6f79; trace=c5479c01-f07c-4c96-82fb-c501b62bea7c,id=c5479c01-f07c-4c96-82fb-c501b62bea7c\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=f5d3f249-76e8-40de-9bd0-3596b77744ea; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=8bfafa50-eddf-4e2d-8860-8e6ce276a622\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=ee59c2f6-c05f-4683-9f58-acfa7287bba4; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=f1302f5c-be7d-4c0e-b22a-92809d5b3700; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=fd6c122b-26b7-40b6-b2f2-1cd06529bbc4; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=8bfafa50-eddf-4e2d-8860-8e6ce276a622\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=fd6c122b-26b7-40b6-b2f2-1cd06529bbc4; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=f1302f5c-be7d-4c0e-b22a-92809d5b3700; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=ee59c2f6-c05f-4683-9f58-acfa7287bba4; trace=f5d3f249-76e8-40de-9bd0-3596b77744ea,id=f5d3f249-76e8-40de-9bd0-3596b77744ea\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=550b93a5-f017-42c2-aabd-bb5e49c5e9ae,id=550b93a5-f017-42c2-aabd-bb5e49c5e9ae\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=040f4ebc-7c1f-4c99-9641-02e9249e8683; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=eb7b1fd1-3359-4a24-a695-10c6c9f483c4\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=16118a64-4277-4b1d-80dc-e32ee7c593ce; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=790b264f-b5c6-4b6b-8de0-e80de3414ba9; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=724a3346-d804-47b2-8b44-4b3d27ee8dfc; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=eb7b1fd1-3359-4a24-a695-10c6c9f483c4\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=724a3346-d804-47b2-8b44-4b3d27ee8dfc; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=790b264f-b5c6-4b6b-8de0-e80de3414ba9; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=16118a64-4277-4b1d-80dc-e32ee7c593ce; trace=040f4ebc-7c1f-4c99-9641-02e9249e8683,id=040f4ebc-7c1f-4c99-9641-02e9249e8683\n"
     ]
    }
   ],
   "source": [
    "#Testing the llm\n",
    "print(llm.invoke(\"What is the capital of France?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e1ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f718a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e218cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data from the data directory\n",
    "#Reading it from Medical_book.pdf\n",
    "def data_loader(Data):\n",
    "    loader= DirectoryLoader(\n",
    "        Data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c383511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pdf= data_loader(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "587f8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the documents into chunks\n",
    "def chunking(data):\n",
    "    text_split= RecursiveCharacterTextSplitter(\n",
    "        chunk_size= 500,  # Size of each chunk\n",
    "        chunk_overlap=50,  # Overlap between chunks\n",
    "    )\n",
    "    text_chunks=text_split.split_documents(data_pdf)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b521da16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of chunks: 5961\n"
     ]
    }
   ],
   "source": [
    "#Creating chunks\n",
    "chunks= chunking(data_pdf)\n",
    "print(f\"Length of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5cf0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/25c_ln015yz7lynkgndt4zfh0000gn/T/ipykernel_34738/3746995020.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings= HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download sentence-transformers/all-MiniLM-L6-v2 embeddings model from hf library\n",
    "embeddings= HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \n",
    ")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1d4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test query: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08204811811447144,\n",
       " 0.036055490374565125,\n",
       " -0.003892861772328615,\n",
       " -0.004881023429334164,\n",
       " 0.02565109170973301,\n",
       " -0.057143475860357285,\n",
       " 0.012191597372293472,\n",
       " 0.004678927827626467,\n",
       " 0.03494987264275551,\n",
       " -0.02242191694676876,\n",
       " -0.008005278185009956,\n",
       " -0.10935358703136444,\n",
       " 0.022724751383066177,\n",
       " -0.029320847243070602,\n",
       " -0.04352203384041786,\n",
       " -0.1202412024140358,\n",
       " -0.0008486161823384464,\n",
       " -0.018150126561522484,\n",
       " 0.0561295747756958,\n",
       " 0.0030852581840008497,\n",
       " 0.002336363075301051,\n",
       " -0.016839278861880302,\n",
       " 0.06362470239400864,\n",
       " -0.02366023138165474,\n",
       " 0.031493522226810455,\n",
       " -0.034797947853803635,\n",
       " -0.020548803731799126,\n",
       " -0.002790980739519,\n",
       " -0.011037993244826794,\n",
       " -0.036126721650362015,\n",
       " 0.05414104461669922,\n",
       " -0.036617130041122437,\n",
       " -0.0250086672604084,\n",
       " -0.038170404732227325,\n",
       " -0.04960361868143082,\n",
       " -0.015148085542023182,\n",
       " 0.021315043792128563,\n",
       " -0.012740432284772396,\n",
       " 0.07670088857412338,\n",
       " 0.04435575753450394,\n",
       " -0.010834893211722374,\n",
       " -0.029760019853711128,\n",
       " -0.016970476135611534,\n",
       " -0.024691836908459663,\n",
       " 0.00808708555996418,\n",
       " 0.043587688356637955,\n",
       " 0.007177503779530525,\n",
       " 0.07550130039453506,\n",
       " 0.03280666097998619,\n",
       " -0.062046412378549576,\n",
       " 0.06677897274494171,\n",
       " 0.027091341093182564,\n",
       " -0.04568944498896599,\n",
       " -0.03144114837050438,\n",
       " -0.031155217438936234,\n",
       " 0.09153681993484497,\n",
       " -0.001788194291293621,\n",
       " -0.011282636784017086,\n",
       " 0.03649932146072388,\n",
       " 0.05692712590098381,\n",
       " 0.0022999942302703857,\n",
       " -0.03775059059262276,\n",
       " -0.015484724193811417,\n",
       " 0.052391454577445984,\n",
       " 0.06036437302827835,\n",
       " -0.0166483111679554,\n",
       " 0.008809956721961498,\n",
       " -0.006622252520173788,\n",
       " -0.10629702359437943,\n",
       " 0.0017158956034108996,\n",
       " -0.04830584302544594,\n",
       " -0.029768697917461395,\n",
       " 0.004325553774833679,\n",
       " -0.08567410707473755,\n",
       " 0.06620793044567108,\n",
       " -0.0551835335791111,\n",
       " -0.11332664638757706,\n",
       " 0.05084019899368286,\n",
       " -0.00931726023554802,\n",
       " 0.006006704643368721,\n",
       " 0.02101273462176323,\n",
       " -0.022515444085001945,\n",
       " 0.0004727463237941265,\n",
       " 0.056389741599559784,\n",
       " 0.04544348269701004,\n",
       " -0.0052775186486542225,\n",
       " 0.09359361231327057,\n",
       " 0.02746027335524559,\n",
       " 0.029441922903060913,\n",
       " -0.04569660499691963,\n",
       " -0.048944342881441116,\n",
       " 0.0013615380739793181,\n",
       " -0.01285338681191206,\n",
       " 0.07980716228485107,\n",
       " -0.11903543770313263,\n",
       " 0.06876879930496216,\n",
       " -0.022718310356140137,\n",
       " 0.04485704004764557,\n",
       " -0.08129201829433441,\n",
       " 0.044057752937078476,\n",
       " 0.002956357318907976,\n",
       " 0.017621012404561043,\n",
       " 0.08311299979686737,\n",
       " -0.018054941669106483,\n",
       " -0.04792353883385658,\n",
       " 0.05866707116365433,\n",
       " 0.00624646432697773,\n",
       " -0.0146567951887846,\n",
       " -0.007337220478802919,\n",
       " -0.07807917147874832,\n",
       " -0.10076915472745895,\n",
       " -0.033526711165905,\n",
       " -0.0009018660639412701,\n",
       " -0.05113115906715393,\n",
       " 0.027221737429499626,\n",
       " 0.07086151093244553,\n",
       " 0.04740167036652565,\n",
       " -0.10456676036119461,\n",
       " 0.004401104524731636,\n",
       " -0.028793778270483017,\n",
       " -0.018355783075094223,\n",
       " -0.05058589205145836,\n",
       " -0.03154188022017479,\n",
       " -0.009517708793282509,\n",
       " -0.060644716024398804,\n",
       " 0.021163931116461754,\n",
       " -0.04660217836499214,\n",
       " -7.755119002722617e-33,\n",
       " -0.03129623830318451,\n",
       " 0.05634508654475212,\n",
       " 0.07738029211759567,\n",
       " 0.06391440331935883,\n",
       " -0.04664717987179756,\n",
       " -0.00757050234824419,\n",
       " -0.05532645061612129,\n",
       " 0.040277592837810516,\n",
       " -0.03152398020029068,\n",
       " -0.007102969102561474,\n",
       " 0.039592351764440536,\n",
       " -0.1317119598388672,\n",
       " -0.06614520400762558,\n",
       " 0.021774915978312492,\n",
       " 0.09698941558599472,\n",
       " 0.011799268424510956,\n",
       " 0.08900414407253265,\n",
       " 0.03468592092394829,\n",
       " -0.04387172311544418,\n",
       " -0.00016685288574080914,\n",
       " 0.014680818654596806,\n",
       " -0.00270934053696692,\n",
       " -0.003317643655464053,\n",
       " 0.017399987205863,\n",
       " 0.06010516732931137,\n",
       " 0.03949520364403725,\n",
       " -0.0017327414825558662,\n",
       " 0.077283576130867,\n",
       " 0.014559619128704071,\n",
       " -0.00219332380220294,\n",
       " -0.0018453457159921527,\n",
       " 0.015014738775789738,\n",
       " 0.02167288400232792,\n",
       " 0.007331369910389185,\n",
       " 0.017999548465013504,\n",
       " 0.049744125455617905,\n",
       " 0.012588215060532093,\n",
       " -0.0026321832556277514,\n",
       " 0.04346171021461487,\n",
       " 0.0629749521613121,\n",
       " 0.06660725176334381,\n",
       " -0.03639739379286766,\n",
       " -0.038729626685380936,\n",
       " 0.04401262849569321,\n",
       " 0.005643496289849281,\n",
       " 0.0056925886310637,\n",
       " -0.0348784439265728,\n",
       " -0.07138058543205261,\n",
       " 0.10089902579784393,\n",
       " -0.024756282567977905,\n",
       " 0.014684423804283142,\n",
       " -0.025919564068317413,\n",
       " -0.07273470610380173,\n",
       " -0.01743422821164131,\n",
       " 0.026018895208835602,\n",
       " 0.11413374543190002,\n",
       " -0.0709296464920044,\n",
       " 0.01804066076874733,\n",
       " -0.0033645431976765394,\n",
       " 0.008468247950077057,\n",
       " -0.003198285587131977,\n",
       " 0.005925253499299288,\n",
       " -0.022993482649326324,\n",
       " 0.07761327922344208,\n",
       " 0.03472591191530228,\n",
       " 0.08739188313484192,\n",
       " 0.04626099020242691,\n",
       " 0.018758663907647133,\n",
       " 0.011047514155507088,\n",
       " -0.04582412168383598,\n",
       " -0.046474333852529526,\n",
       " 0.026539448648691177,\n",
       " 0.07402203232049942,\n",
       " 0.06560056656599045,\n",
       " 0.06272169947624207,\n",
       " 0.07237666845321655,\n",
       " -0.008960544131696224,\n",
       " -0.035324882715940475,\n",
       " -0.005384529009461403,\n",
       " -0.0032188689801841974,\n",
       " -0.03802553564310074,\n",
       " -0.04136469587683678,\n",
       " -0.09670207649469376,\n",
       " 0.0442192368209362,\n",
       " -0.033506330102682114,\n",
       " -0.07136603444814682,\n",
       " -0.01164279319345951,\n",
       " -0.0071111805737018585,\n",
       " 0.00064536661375314,\n",
       " -0.08838038146495819,\n",
       " -0.11334280669689178,\n",
       " -0.12120427191257477,\n",
       " -0.0013210901524871588,\n",
       " -0.04424310848116875,\n",
       " -0.08665942400693893,\n",
       " 3.9976880445176384e-33,\n",
       " 0.025276146829128265,\n",
       " -0.0026350265834480524,\n",
       " -0.0811300128698349,\n",
       " 0.02546190284192562,\n",
       " 0.0013292018556967378,\n",
       " 0.016038086265325546,\n",
       " 0.09549155831336975,\n",
       " 0.03321703523397446,\n",
       " -0.012048923410475254,\n",
       " 0.01698562316596508,\n",
       " -0.08307887613773346,\n",
       " -0.12452160567045212,\n",
       " 0.04390959069132805,\n",
       " 0.012151052244007587,\n",
       " 0.06574592739343643,\n",
       " 0.10052961856126785,\n",
       " 0.07295702397823334,\n",
       " -0.026920225471258163,\n",
       " -0.03218478336930275,\n",
       " -0.053466882556676865,\n",
       " -0.12637238204479218,\n",
       " 0.0053980727680027485,\n",
       " -0.035390954464673996,\n",
       " -0.004280008841305971,\n",
       " -0.025039497762918472,\n",
       " 0.041625600308179855,\n",
       " -0.0999334305524826,\n",
       " -0.047652747482061386,\n",
       " -0.023976033553481102,\n",
       " 0.0026398340705782175,\n",
       " -0.055190958082675934,\n",
       " 0.013548423536121845,\n",
       " 0.04904061555862427,\n",
       " 0.08499682694673538,\n",
       " -0.042024608701467514,\n",
       " 0.07673397660255432,\n",
       " 0.033213112503290176,\n",
       " 0.001265315106138587,\n",
       " 0.039995044469833374,\n",
       " 0.06455172598361969,\n",
       " -0.043372634798288345,\n",
       " -0.04965050891041756,\n",
       " 0.05795808881521225,\n",
       " 0.11267867684364319,\n",
       " 0.07069908827543259,\n",
       " 0.008226506412029266,\n",
       " 0.04381539300084114,\n",
       " -0.022527901455760002,\n",
       " -0.007248724810779095,\n",
       " 0.04985780268907547,\n",
       " 0.038604963570833206,\n",
       " 0.0679117739200592,\n",
       " -0.04107004031538963,\n",
       " 0.0057322075590491295,\n",
       " 0.017908023670315742,\n",
       " 0.04930576682090759,\n",
       " -0.05145525559782982,\n",
       " 0.05103078857064247,\n",
       " -0.09380979090929031,\n",
       " -0.06816750019788742,\n",
       " 0.0652628019452095,\n",
       " 0.0754573866724968,\n",
       " -0.016841862350702286,\n",
       " 0.0661250650882721,\n",
       " -0.002897112164646387,\n",
       " -0.02073814906179905,\n",
       " -0.1270085573196411,\n",
       " 0.061604779213666916,\n",
       " -0.009813145734369755,\n",
       " -0.014706120826303959,\n",
       " 0.13544602692127228,\n",
       " 0.03413687273859978,\n",
       " -0.06481858342885971,\n",
       " 0.05101705342531204,\n",
       " -0.06637553870677948,\n",
       " 0.029188325628638268,\n",
       " 0.07939162850379944,\n",
       " 0.014440285973250866,\n",
       " -0.027310028672218323,\n",
       " 0.005267048254609108,\n",
       " -0.06761956214904785,\n",
       " -0.02049443870782852,\n",
       " -0.027144720777869225,\n",
       " -0.026149796321988106,\n",
       " -0.07054673135280609,\n",
       " 0.034717947244644165,\n",
       " 0.0076125492341816425,\n",
       " -0.10216667503118515,\n",
       " 0.05842781439423561,\n",
       " -0.07478595525026321,\n",
       " -0.02196803316473961,\n",
       " -0.0068086604587733746,\n",
       " -0.051303282380104065,\n",
       " -0.0369698666036129,\n",
       " 0.025690196081995964,\n",
       " -1.7501511351269983e-08,\n",
       " 0.06809662282466888,\n",
       " 0.04500091075897217,\n",
       " -0.044086355715990067,\n",
       " 0.012878752313554287,\n",
       " -0.05775946378707886,\n",
       " -0.09547640383243561,\n",
       " 0.06219944357872009,\n",
       " -0.004272663500159979,\n",
       " -0.008670181967318058,\n",
       " 0.00025496413582004607,\n",
       " -0.07361152023077011,\n",
       " 0.056062161922454834,\n",
       " -0.06970258802175522,\n",
       " -0.051116276532411575,\n",
       " -0.04102282598614693,\n",
       " -0.004761020187288523,\n",
       " -0.03246321156620979,\n",
       " 0.04304734990000725,\n",
       " 0.0086831608787179,\n",
       " 0.02270783670246601,\n",
       " -0.004905324429273605,\n",
       " 0.023357952013611794,\n",
       " -0.04563941806554794,\n",
       " -0.05810334533452988,\n",
       " 0.012541470117866993,\n",
       " -0.09903229773044586,\n",
       " 0.04062921181321144,\n",
       " 0.045668892562389374,\n",
       " 0.0027159014716744423,\n",
       " -0.005313029512763023,\n",
       " 0.066402867436409,\n",
       " -0.027287572622299194,\n",
       " -0.050074830651283264,\n",
       " -0.0902949795126915,\n",
       " -0.03612229973077774,\n",
       " 0.012680075131356716,\n",
       " -0.005830484442412853,\n",
       " -0.0050932737067341805,\n",
       " 0.009507523849606514,\n",
       " -0.029052456840872765,\n",
       " 0.09497950971126556,\n",
       " 0.061990685760974884,\n",
       " 0.012536618858575821,\n",
       " -0.01196106243878603,\n",
       " 0.024525681510567665,\n",
       " 0.04538298025727272,\n",
       " 0.05382111296057701,\n",
       " -0.03517722338438034,\n",
       " 0.11464708298444748,\n",
       " -0.0890202447772026,\n",
       " -0.11148510873317719,\n",
       " 0.09941158443689346,\n",
       " 0.003938894718885422,\n",
       " 0.004478404298424721,\n",
       " 0.0034466234501451254,\n",
       " 0.0708964616060257,\n",
       " -0.051293615251779556,\n",
       " -0.01267421804368496,\n",
       " 0.021874727681279182,\n",
       " -0.020012008026242256,\n",
       " -0.014911332167685032,\n",
       " 0.04920434206724167,\n",
       " 0.08929190039634705,\n",
       " -0.011127772741019726]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing Embeddings Model\n",
    "test_query= embeddings.embed_query(\"What is the capital of France?\")\n",
    "print(f\"Length of test query: {len(test_query)}\")\n",
    "test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f34c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ced325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "name_index=\"rag-pinecone-llama2-chatbot\"\n",
    "\n",
    "doc_embed = Pinecone.from_texts(\n",
    "    [chunk.page_content for chunk in chunks],\n",
    "    embeddings,\n",
    "    index_name=name_index,\n",
    "    # Add these if required by your version:\n",
    "    # pinecone_api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    # environment=os.getenv(\"PINECONE_ENVIRONMENT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf7179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 semantic results for query 'What are the symptoms of diabetes?': \n",
      "[Document(page_content='affected and can range greatly.\\n• Type I diabetes mellitus. Characterized by fatigue and\\nan abnormally high level of glucose in the blood\\n(hyperglycemia).\\n• Amyotrophic lateral schlerosis. First signs are stum-\\nbling and difficulty climbing stairs. Later, muscle\\ncramps and twitching may be observed as well as\\nweakness in the hands making fastening buttons or\\nturning a key difficult. Speech may become slowed or\\nslurred. There may also be difficluty swallowing. As'), Document(page_content='begin to fall. A person with diabetes mellitus either does\\nnot make enough insulin, or makes insulin that does not\\nwork properly. The result is blood sugar that remains\\nhigh, a condition called hyperglycemia.\\nDiabetes must be diagnosed as early as possible. If\\nleft untreated, it can damage or cause failure of the eyes,\\nkidneys, nerves, heart, blood vessels, and other body\\norgans. Hypoglycemia, or low blood sugar, may also be\\ndiscovered through blood sugar testing. Hypoglycemia is'), Document(page_content='Resources\\nBOOKS\\nA Manual of Laboratory and Diagnostic Tests.5th ed. Ed.\\nFrancis Fishback. Philadelphia: Lippincott, 1996.\\nHenry, John B., ed. Clinical Diagnosis and Management by\\nLaboratory Methods. 19th ed. Philadelphia: W. B. Saun-\\nders Co., 1996.\\nPERIODICALS\\nAmerican Diabetes Association. “Report of the Expert Com-\\nmittee on the Diagnosis and Classification of Diabetes\\nMellitus.” Diabetes Care 20, no, 7(July 997): 1183-1197.\\nORGANIZATIONS')]\n"
     ]
    }
   ],
   "source": [
    "#Retrieving top 3 results based on similarity search from the index\n",
    "\n",
    "#Code for loading existing index\n",
    "index_search= Pinecone.from_existing_index(\n",
    "    index_name=name_index,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "query=\"What are the symptoms of diabetes?\"\n",
    "semantic_search= index_search.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"Top 3 semantic results for query '{query}': \\n{semantic_search}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fae48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template= \"\"\"You are a medical expert. \\\n",
    "Given the following context from medical documents, answer the following questions.\\\n",
    "    If you don't know answer or no relevant documents with context have been retrieved, say 'I don't know'.\\\n",
    "       context:  {context}\\\n",
    "        question: {question}\\\n",
    "            Just share helpful answers, nothing else\n",
    "            Helpful Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73d557b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt= PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs= {\"prompt\": Prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3593ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RetrievalQA chain\n",
    "chatbot_chain= RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever= index_search.as_retriever(search_kwargs={'k': 3}),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f5dd181",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExiting the chatbot. Goodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m response\u001b[38;5;241m=\u001b[39m \u001b[43mchatbot_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/retrieval_qa/base.py:153\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:602\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    598\u001b[0m         _output_key\n\u001b[1;32m    599\u001b[0m     ]\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    603\u001b[0m         _output_key\n\u001b[1;32m    604\u001b[0m     ]\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:380\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    378\u001b[0m }\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/combine_documents/base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/combine_documents/stuff.py:257\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/llm.py:315\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:380\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    378\u001b[0m }\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/llm.py:125\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    122\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    123\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 125\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain/chains/llm.py:137\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    145\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/language_models/llms.py:750\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    744\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    748\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    749\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/language_models/llms.py:944\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    931\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    932\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         )\n\u001b[1;32m    943\u001b[0m     ]\n\u001b[0;32m--> 944\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/language_models/llms.py:787\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    786\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 787\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    788\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_core/language_models/llms.py:774\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    766\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    771\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 774\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    782\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    783\u001b[0m         )\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_community/llms/ollama.py:429\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 429\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_community/llms/ollama.py:347\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    340\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[1;32m    346\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[1;32m    349\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/langchain_community/llms/ollama.py:192\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    186\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    191\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[1;32m    193\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[1;32m    194\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    195\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    197\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/requests/models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[1;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[1;32m    871\u001b[0m ):\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/requests/utils.py:562\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    561\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    563\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/urllib3/response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/urllib3/response.py:828\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/site-packages/urllib3/response.py:758\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/RAG_Pinecone_Llama2_Chatbot/env/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question= input(f\"Enter your query: \")\n",
    "    if question.lower() == \"exit\":\n",
    "        print(\"Exiting the chatbot. Goodbye!\")\n",
    "        break\n",
    "    response= chatbot_chain.invoke({\"query\": question})\n",
    "    print(f\"Response: {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Response: {response['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0855f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RetrievalQA chain\n",
    "'''qa_chain= RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=index_search.as_retriever(),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
